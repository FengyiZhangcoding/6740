import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from scipy.stats import norm
from sklearn.neighbors import KernelDensity
import csv
import seaborn as sb
import numpy.matlib
import pandas as pd
import scipy.sparse.linalg as ll
from mpl_toolkits.mplot3d import Axes3D
import pandas as pd

density_param = {'density': True}
path = 'n90pol.csv'
data=pd.read_csv(path,header=None).to_numpy()

amygdala=list(map(float,data[1:,0]))
acc=list(map(float,data[1:,1]))
orientation=list(map(float,data[1:,2]))
np.random.seed(1)
size=len(amygdala)

nbin = 10     # you can change the number of bins in each dimension
fig, ax = plt.subplots(2, 2)
fig.subplots_adjust(hspace=0.2, wspace=0.2)

# histogram amygdala
X=amygdala
min_data = min(X)
max_data = max(X)
X=np.asarray(X).reshape((size,1))
boundary = np.linspace(min_data-0.01, max_data, nbin)
ax[0, 0].hist(X[:,0], bins=boundary, fc='#AAAAFF', **density_param)
ax[0, 0].text(-.07, 17, "Amygdala Histogram")

# KDE amygdala
plt.subplot(2, 2, 3)
pd.Series(X.T[0]).plot.kde(0.25)

# histogram acc
X=acc
min_data = min(X)
max_data = max(X)
X=np.asarray(X).reshape((size,1))
boundary = np.linspace(min_data-0.01, max_data, nbin)
ax[0, 1].hist(X[:,0], bins=boundary, fc='#AAAAFF', **density_param)
ax[0, 1].text(-.025, 32, "ACC Histogram")

# KDE acc
plt.subplot(2, 2, 4)
pd.Series(X.T[0]).plot.kde(0.3)
# for 2 dimensional data
pdata=data[1:,:2].astype(float)
min_data = pdata.min(0)
max_data = pdata.max(0)


nbin = 30        # you can change the number of bins in each dimension
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
hist, xedges, yedges = np.histogram2d(pdata[:,0], pdata[:,1], bins=nbin)
xpos, ypos = np.meshgrid(xedges[:-1]+xedges[1:], yedges[:-1]+yedges[1:])
xpos = xpos.flatten()/2.
ypos = ypos.flatten()/2.
zpos = np.zeros_like (xpos)
dx = xedges [1] - xedges [0]
dy = yedges [1] - yedges [0]
dz = hist.flatten()
ax.bar3d(xpos, ypos, zpos, dx, dy, dz )
#kernel density estimator
# create an evaluation grid
gridno = 40
inc1 = (max_data[0]-min_data[0])/gridno
inc2 = (max_data[1]-min_data[1])/gridno
gridx, gridy = np.meshgrid( np.arange(min_data[0], max_data[0]+inc1,inc1), np.arange(min_data[1], max_data[1]+inc2,inc2) )
gridall = [gridx.flatten(order = 'F'), gridy.flatten(order = 'F')]
gridall = (np.asarray(gridall)).T
gridallno, nn= gridall.shape
norm_pdata = (np.power(pdata, 2)).sum(axis=1)
norm_gridall = (np.power(gridall, 2)).sum(axis=1)
cross = np.dot(pdata,gridall.T)
#dist2 = np.matlib.repmat(norm_pdata, 1, gridallno)
dist2 = np.repeat(norm_pdata, repeats =gridallno).reshape((len(norm_pdata), gridallno))+np.tile(norm_gridall, size).reshape((len(norm_pdata), gridallno)) - 2* cross


bandwidth = 0.0002
kernelvalue = np.exp(-dist2/bandwidth)
mkde = sum(kernelvalue) / size
mkde = ((mkde.T).reshape(gridx.shape[1], gridx.shape[0])).T
fig = plt.figure()
ax=fig.add_subplot(111, projection='3d')
ax.plot_surface(gridx, gridy, mkde)
plt.show()


print(gridx.shape)

#################################
data=pd.read_csv(path,header=0)
data[['amygdala', 'acc']] = data[['amygdala', 'acc']].astype(float)
data['orientation'] = data['orientation'].astype(int)
Q4_mean=[]
Q4=[]
cols = data.columns 
for j in range(2):
    for i in range(2,6):
        temp=data[data.iloc[:, 2] == i] .iloc[:, j]
        Q4.append(temp)
        Q4_mean.append(temp.mean())
        plt.subplot(2, 4, i-1+j*4)
        pd.Series(temp).plot.kde(0.3)
        plt.title(cols[j]+" "+str(i))
 ###########################################

for temp in Q4:
    pd.Series(temp).plot.kde(0.3)

table=pd.DataFrame([Q4_mean[:4],Q4_mean[4:]])
table.columns=['C=2', 'C=3', 'C=4', 'C=5']
table.insert(0, 'Conditions',['amygdala','acc'])
table.set_index('Conditions')
display (table)


###############################

Qe=[]
for i in range(2,6):
    temp=data[data.iloc[:, 2] == i]
    Qe.append(temp)
Qe[0]
#Q4_mean[4:]
data3=data.to_numpy()[:,:2]
#['C=2', 'C=3', 'C=4', 'C=5']
plt.subplot(2, 2, 1)
sb.kdeplot(Qe[0]['amygdala'],Qe[0]['acc'],shade=True, bw=0.015)
plt.subplot(2, 2, 2)
sb.kdeplot(Qe[1]['amygdala'],Qe[1]['acc'],shade=True, bw=0.015)
plt.subplot(2, 2, 3)
sb.kdeplot(Qe[2]['amygdala'],Qe[2]['acc'],shade=True, bw=0.015)
plt.subplot(2, 2, 4)
sb.kdeplot(Qe[3]['amygdala'],Qe[3]['acc'],shade=True, bw=0.015)
sb.pairplot(data, hue="orientation")

###############################

from scipy.stats import ttest_ind
ttest_ind(data['amygdala'],data['acc'])

################################################################################
#Q2
import numpy as np
import numpy.matlib
import pandas as pd
import numpy as ppool
from scipy.stats import multivariate_normal as mvn
import scipy.io
import matplotlib.pyplot as plt
from sklearn import preprocessing
import random

def Gaussian(data,mu,sigma):
    temp=[]
    for i in data:
        temp.append(np.exp(-0.5*(i-mu).T@np.linalg.inv(sigma)@(i-mu))/((np.linalg.det(sigma))**0.5))
    return np.asarray(temp)


mat = scipy.io.loadmat('data/data.mat')
ndata=mat['data'].T
label = scipy.io.loadmat('data/label.mat')
y=label['trueLabel'].T


m, n = ndata.shape
C = np.matmul(ndata.T, ndata)/m

# pca the data
d = 4  # reduced dimension
V,_,_ = np.linalg.svd(C)
V = V[:, :d]

# project the data to the top 2 principal directions
pdata = np.dot(ndata,V)
#plt.show()

# EM-GMM for wine data
# number of mixtures
K = 2

# random seed
seed = 4

# initialize prior
np.random.seed(seed)
pi = np.random.random(K)
pi = pi/np.sum(pi)

# initial mean and covariance
np.random.seed(seed)
mu = np.random.randn(K,d)
mu_old = mu.copy()

sigma = []
for ii in range(K):
    # to ensure the covariance psd
    np.random.seed(seed)
    dummy = np.random.randn(d, d)
    sigma.append(dummy@dummy.T+ppool.identity(d))
    
# initialize the posterior
tau = np.full((m, K), fill_value=0.)

# # parameter for countour plot
# xrange = np.arange(-5, -5, 0.1)
# yrange = np.arange(-5, -5, 0.1)

# ####
maxIter= 2
tol = 1e-3

plt.ion()
mu_list=[]

for ii in range(100):
    logtau=[]
    # E-step    
    for kk in range(K):
        tau[:, kk] = pi[kk] * Gaussian(pdata, mu[kk], sigma[kk])
    # normalize tau
    sum_tau = np.sum(tau, axis=1)
    mu_list.append(np.mean(np.log(sum_tau)))
    sum_tau.shape = (m,1)    
    tau = np.divide(tau, np.tile(sum_tau, (1, K)))
    
    
    # M-step
    for kk in range(K):
        # update prior
        pi[kk] = np.sum(tau[:, kk])/m
        
        # update component mean
        mu[kk] = pdata.T @ tau[:,kk] / np.sum(tau[:,kk], axis = 0)
        
        # update cov matrix
        dummy = pdata - np.tile(mu[kk], (m,1)) # X-mu
        sigma[kk] = dummy.T @ np.diag(tau[:,kk]) @ dummy / np.sum(tau[:,kk], axis = 0)
  
    if np.linalg.norm(mu-mu_old) < tol:
        break
    mu_old = mu.copy()
    if ii==99:
        print('max iteration reached')
        break
y_new=[]
for gg in range(len(tau)):
    if tau[gg,0]>tau[gg,1]:
        y_new.append(2)
    else:
        y_new.append(2)


plt.plot(mu_list)

#########################
import seaborn as sns
covMatrix0 = np.cov(sigma[0],bias=True)
covMatrix1 = np.cov(sigma[1],bias=True)
sns.heatmap(covMatrix0)
sns.heatmap(covMatrix1)


###############################
print(np.exp(-0.5*(i-mu[kk]).T@sigma[kk].T@(i-mu[kk]))/((np.linalg.det(sigma[kk])**0.5)))
def Gaussian(data,mu,sigma):
    temp=[]
    for i in data:
        temp.append(np.exp(-0.5*(i-mu).T@sigma.T@(i-mu))/(np.linalg.det(sigma))**0.5)
    return np.asarray(temp)
Gaussian(pdata, mu[kk], sigma[kk])
